from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os
from dotenv import load_dotenv
import openai

from openai import OpenAI  # âœ… v1.xìš© í´ë¼ì´ì–¸íŠ¸

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class Message(BaseModel):
    message: str

@app.post("/api/ask")
async def ask_gpt(request: Message):
    try:
        print(f"ğŸ”¥ ì§ˆë¬¸ ìˆ˜ì‹ : {request.message}")

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§„ë¡œ ì„¤ê³„ë¥¼ ë„ì™€ì£¼ëŠ” AI ì±—ë´‡ì´ì•¼."},
                {"role": "user", "content": request.message}
            ]
        )

        reply = response.choices[0].message.content
        print(f"âœ… GPT ì‘ë‹µ: {reply}")

        return { "reply": reply }

    except Exception as e:
        print("âŒ OpenAI ì˜¤ë¥˜:", e)
        return { "error": str(e) }
